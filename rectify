import cv2
import os
import numpy as np
import yaml
from glob import glob
import cv2.ximgproc as xip

def read_full_T_BS(yaml_file):
    with open(yaml_file, 'r') as f:
        data = yaml.safe_load(f)
        fx, fy, cx, cy = data['intrinsics']
        K = np.array([[fx, 0, cx],
                      [0, fy, cy],
                      [0,  0,  1]], dtype=np.float64)
        D = np.array(data['distortion_coefficients'], dtype=np.float64)
        T_BS = np.array(data['T_BS']['data'], dtype=np.float64).reshape(4, 4)
        return K, D, T_BS

def load_image_pairs(cam0_path, cam1_path):
    cam0_images = sorted(glob(os.path.join(cam0_path, '*.png')))
    cam1_images = sorted(glob(os.path.join(cam1_path, '*.png')))
    return list(zip(cam0_images, cam1_images))

def write_ply(filename, points, colors=None):
    with open(filename, 'w') as f:
        f.write(f"ply\nformat ascii 1.0\nelement vertex {len(points)}\n")
        f.write("property float x\nproperty float y\nproperty float z\n")
        if colors is not None:
            f.write("property uchar red\nproperty uchar green\nproperty uchar blue\n")
        f.write("end_header\n")
        for i, p in enumerate(points):
            if colors is not None:
                c = colors[i]
                f.write(f"{p[0]} {p[1]} {p[2]} {c[0]} {c[1]} {c[2]}\n")
            else:
                f.write(f"{p[0]} {p[1]} {p[2]}\n")

# === Paths ===
root = r"C:\Users\Siddh\Desktop\reconstruction\mav0"
left_yaml = os.path.join(root, 'cam0', 'sensor.yaml')
right_yaml = os.path.join(root, 'cam1', 'sensor.yaml')
left_imgs = os.path.join(root, 'cam0', 'data')
right_imgs = os.path.join(root, 'cam1', 'data')

# === Output folder ===
output_dir = "output_pointclouds"
os.makedirs(output_dir, exist_ok=True)

# === Calibration ===
K_left, D_left, T_left = read_full_T_BS(left_yaml)
K_right, D_right, T_right = read_full_T_BS(right_yaml)

T_lr = np.linalg.inv(T_left) @ T_right
R = T_lr[:3, :3]
t = T_lr[:3, 3].reshape(3, 1)

image_size = (752, 480)
R1, R2, P1, P2, Q, _, _ = cv2.stereoRectify(
    K_left, D_left, K_right, D_right, image_size, R, t,
    flags=cv2.CALIB_ZERO_DISPARITY, alpha=0
)

left_map1, left_map2 = cv2.initUndistortRectifyMap(
    K_left, D_left, R1, P1, image_size, cv2.CV_16SC2)
right_map1, right_map2 = cv2.initUndistortRectifyMap(
    K_right, D_right, R2, P2, image_size, cv2.CV_16SC2)

# === Load all pairs ===
pairs = load_image_pairs(left_imgs, right_imgs)

# === Stereo matchers ===
left_matcher = cv2.StereoSGBM_create(
    minDisparity=0,
    numDisparities=128,
    blockSize=7,
    P1=8 * 3 * 7 ** 2,
    P2=32 * 3 * 7 ** 2,
    disp12MaxDiff=1,
    uniquenessRatio=10,
    speckleWindowSize=100,
    speckleRange=32,
    preFilterCap=63,
    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY
)
right_matcher = xip.createRightMatcher(left_matcher)
wls_filter = xip.createDisparityWLSFilter(matcher_left=left_matcher)
wls_filter.setLambda(8000)
wls_filter.setSigmaColor(1.5)

print(f"[INFO] Processing {len(pairs)} frames...")

for idx, (left_path, right_path) in enumerate(pairs):
    left_img = cv2.imread(left_path, cv2.IMREAD_GRAYSCALE)
    right_img = cv2.imread(right_path, cv2.IMREAD_GRAYSCALE)
    if left_img is None or right_img is None:
        continue

    left_rect = cv2.remap(left_img, left_map1, left_map2, cv2.INTER_LINEAR)
    right_rect = cv2.remap(right_img, right_map1, right_map2, cv2.INTER_LINEAR)

    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    left_eq = clahe.apply(left_rect)
    right_eq = clahe.apply(right_rect)

    disp_left = left_matcher.compute(left_eq, right_eq)
    disp_right = right_matcher.compute(right_eq, left_eq)
    filtered_disp = wls_filter.filter(disp_left, left_eq, disparity_map_right=disp_right)

    # Filter disparity values
    filtered_disp = np.clip(filtered_disp, 0, 128)
    filtered_disp = filtered_disp.astype(np.float32) / 16.0
    mask = filtered_disp > 0

    points_3D = cv2.reprojectImageTo3D(filtered_disp, Q)
    points = points_3D[mask]

    # Optional: add grayscale color
    colors = cv2.cvtColor(left_rect, cv2.COLOR_GRAY2BGR)[mask]

    # Save point cloud
    ply_path = os.path.join(output_dir, f"cloud_{idx:03d}.ply")
    write_ply(ply_path, points, colors)
    print(f"[{idx+1}/{len(pairs)}] Saved: {ply_path}")

print("[DONE] All frames processed. You can now merge the PLY files into a full map.")
